@inproceedings{albergoUnderstandingXacroMisunderstandings2022,
  title = {Understanding {{Xacro Misunderstandings}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Albergo, Nicholas and Rathi, Vivek and Ore, John-Paul},
  date = {2022-05},
  pages = {6247--6252},
  doi = {10.1109/ICRA46639.2022.9812349},
  url = {https://ieeexplore.ieee.org/document/9812349/?arnumber=9812349},
  urldate = {2024-12-05},
  abstract = {The Xacro XML macro language can be used to augment the Universal Robot Description Format (URDF) and is part of a critical toolchain from geometric representations to simulation, visualization, and system execution. However, mem-bers of the robotics community, especially newcomers, struggle to troubleshoot and understand the interplay between systems and the Xacro preprocessing pipeline. To better understand how system developers struggle with Xacros, we manually examine 712 Xacro-related questions from the question and answer site answers.ros.org and find Xacro misunderstandings fit into eight key categories using a systematic, qualitative approach called Open Coding. By examining the 'tags' applied to questions, we further find that Xacro problems manifest in a befuddlingly broad set of contexts. This hinders onboarding and complicates system developers' understanding of representations and tools in the Robot Operating System. We aim to provide an empirical grounding that identifies and prioritizes impediments to users of open robotics systems, so that tool designers, teachers, and robotics practitioners can devise ways of improving robot software tooling and education.},
  eventtitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  keywords = {Education,Grounding,Meth-ods and Tools for Robot System Design,Operating systems,Pipelines,Software Tools for Robot Programming,Software-Hardware Integration for Robot Systems,Systematics,Visualization,XML},
  file = {C\:\\Users\\noiri\\Zotero\\storage\\DTGUH3TA\\Albergo et al. - 2022 - Understanding Xacro Misunderstandings.pdf;C\:\\Users\\noiri\\Zotero\\storage\\672PVYYA\\9812349.html}
}

@software{alejhernandezcorderoandrohernandezcorderoRos_gzRos_gz_bridgeTest,
  title = {Ros\_gz/Ros\_gz\_bridge/Test/Config/Full.Yaml at Ros2 · Gazebosim/Ros\_gz},
  author = {AlejHernández Corderoandro Hernández Cordero, Alejandro},
  url = {https://github.com/gazebosim/ros_gz/blob/ros2/ros_gz_bridge/test/config/full.yaml},
  urldate = {2024-12-05},
  abstract = {Integration between ROS (1 and 2) and Gazebo simulation - gazebosim/ros\_gz},
  version = {Alejandro Hernández Cordero},
  file = {C:\Users\noiri\Zotero\storage\DBGX4XWC\ros_gz_bridge.html}
}

@online{AnswerDisadvantageUsing2021,
  title = {Answer to "{{Disadvantage}} of Using --Allow-Releaseinfo-Change for Apt-Get Update"},
  date = {2021-08-30},
  url = {https://stackoverflow.com/a/68990686/27774705},
  urldate = {2025-04-03},
  organization = {Stack Overflow},
  file = {C:\Users\noiri\Zotero\storage\Y7R9NU5L\disadvantage-of-using-allow-releaseinfo-change-for-apt-get-update.html}
}

@article{antonettiAdvancedEnvironmentalStatistics,
  title = {Advanced {{Environmental Statistics}} – {{HS}} 2024, {{Lesson}} 06 – {{Homework Assignment}}},
  author = {Antonetti, Manuel},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\T3JLK6EV\Antonetti - Advanced Environmental Statistics – HS 2024, Lesson 06 – Homework Assignment.pdf}
}

@online{Aptget8AptDebian,
  title = {Apt-Get(8) — Apt — {{Debian}} Unstable — {{Debian Manpages}}},
  url = {https://manpages.debian.org/unstable/apt/apt-get.8.en.html},
  urldate = {2025-04-03},
  file = {C:\Users\noiri\Zotero\storage\KMRHSA6T\apt-get.8.en.html}
}

@online{Aptsecure8AptDebian,
  title = {Apt-Secure(8) — Apt — {{Debian}} Unstable — {{Debian Manpages}}},
  url = {https://manpages.debian.org/unstable/apt/apt-secure.8.en.html},
  urldate = {2025-04-03},
  file = {C:\Users\noiri\Zotero\storage\KFF7WE5T\apt-secure.8.en.html}
}

@software{asadaTasada038Fuzzy_controller_ros2024,
  title = {Tasada038/Fuzzy\_controller\_ros},
  author = {Asada, Takumi},
  date = {2024-11-19T11:35:19Z},
  origdate = {2022-12-21T04:12:01Z},
  url = {https://github.com/tasada038/fuzzy_controller_ros},
  urldate = {2025-03-03},
  abstract = {ROS2 package for fuzzy control.},
  keywords = {cpp,fuzzy-logic,ros2}
}

@online{automaticaddisonCompleteGuideDocker2024,
  title = {The {{Complete Guide}} to {{Docker}} for {{ROS}} 2 {{Jazzy Projects}}},
  author = {{automaticaddison}},
  date = {2024-12-24},
  url = {https://automaticaddison.com/the-complete-guide-to-docker-for-ros-2-jazzy-projects/},
  urldate = {2025-03-05},
  langid = {american},
  file = {C:\Users\noiri\Zotero\storage\YINPW6EB\the-complete-guide-to-docker-for-ros-2-jazzy-projects.html}
}

@online{automaticaddisonHowInstallROS2024,
  title = {How to {{Install ROS}} 2 {{Navigation}} ({{Nav2}}) – {{ROS}} 2 {{Jazzy}}},
  author = {{automaticaddison}},
  date = {2024-11-27},
  url = {https://automaticaddison.com/how-to-install-ros-2-navigation-nav2-ros-2-jazzy/},
  urldate = {2025-04-09},
  langid = {american},
  file = {C:\Users\noiri\Zotero\storage\VEXJRE8J\how-to-install-ros-2-navigation-nav2-ros-2-jazzy.html}
}

@online{automaticaddisonUsefulWorldFiles2021,
  title = {Useful {{World Files}} for {{Gazebo}} and {{ROS}} 2 {{Simulations}}},
  author = {{automaticaddison}},
  date = {2021-09-25},
  url = {https://automaticaddison.com/useful-world-files-for-gazebo-and-ros-2-simulations/},
  urldate = {2025-03-03},
  langid = {american},
  file = {C:\Users\noiri\Zotero\storage\TPE2NZUV\useful-world-files-for-gazebo-and-ros-2-simulations.html}
}

@article{boettigerIntroductionDockerReproducible2015,
  title = {An Introduction to {{Docker}} for Reproducible Research},
  author = {Boettiger, Carl},
  date = {2015-01-20},
  journaltitle = {ACM SIGOPS Operating Systems Review},
  shortjournal = {SIGOPS Oper. Syst. Rev.},
  volume = {49},
  number = {1},
  pages = {71--79},
  issn = {0163-5980},
  doi = {10.1145/2723872.2723882},
  url = {https://dl.acm.org/doi/10.1145/2723872.2723882},
  urldate = {2025-03-23},
  abstract = {As computational work becomes more and more integral to many aspects of scientific research, computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike. Though computational reproducibility seems more straight forward than replicating physical experiments, the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge. In this paper, I explore common reasons that code developed for one research project cannot be successfully executed or extended by subsequent researchers. I review current approaches to these issues, including virtual machines and workflow systems, and their limitations. I then examine how the popular emerging technology Docker combines several areas from systems research - such as operating system virtualization, cross-platform portability, modular re-usable elements, versioning, and a 'DevOps' philosophy, to address these challenges. I illustrate this with several examples of Docker use with a focus on the R statistical environment.},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\IM47WXAG\Boettiger - 2015 - An introduction to Docker for reproducible research.pdf}
}

@video{briandouglasPIDControlBrief2012,
  entrysubtype = {video},
  title = {{{PID Control}} - {{A}} Brief Introduction},
  editor = {{Brian Douglas}},
  editortype = {director},
  date = {2012-12-14},
  url = {https://www.youtube.com/watch?v=UR0hOmjaHp0},
  urldate = {2025-03-03}
}

@video{briandouglasSimpleExamplesPID2012,
  entrysubtype = {video},
  title = {Simple {{Examples}} of {{PID Control}}},
  editor = {{Brian Douglas}},
  editortype = {director},
  date = {2012-12-22},
  url = {https://www.youtube.com/watch?v=XfAt6hNV8XM},
  urldate = {2025-03-03}
}

@online{chowDisadvantageUsingAllowreleaseinfochange2021,
  type = {Forum post},
  title = {Disadvantage of Using --Allow-Releaseinfo-Change for Apt-Get Update},
  author = {Chow, Jonathan},
  date = {2021-08-19},
  url = {https://stackoverflow.com/q/68849201/27774705},
  urldate = {2025-04-03},
  organization = {Stack Overflow},
  file = {C:\Users\noiri\Zotero\storage\BNVWMKIJ\disadvantage-of-using-allow-releaseinfo-change-for-apt-get-update.html}
}

@online{cleggBuildingMultiArchitectureContainers2022,
  title = {Building {{Multi-Architecture Containers}} for {{OCI}} with {{Docker}}},
  author = {Clegg, Tim},
  date = {2022-05-23T11:02:29},
  url = {https://medium.com/@timclegg/building-multi-architecture-containers-for-oci-with-docker-59cea3b5a8c4},
  urldate = {2025-03-05},
  abstract = {How to build multi-architecture (arm64 and amd64) containers for Oracle Cloud Infrastructure with Docker Desktop and Docker Engine.},
  langid = {english},
  organization = {Medium},
  file = {C:\Users\noiri\Zotero\storage\7PPY6E4R\building-multi-architecture-containers-for-oci-with-docker-59cea3b5a8c4.html}
}

@article{coldingIncrementalDemiseUrban2020,
  title = {The {{Incremental Demise}} of {{Urban Green Spaces}}},
  author = {Colding, Johan and Gren, Åsa and Barthel, Stephan},
  date = {2020-05},
  journaltitle = {Land},
  volume = {9},
  number = {5},
  pages = {162},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-445X},
  doi = {10.3390/land9050162},
  url = {https://www.mdpi.com/2073-445X/9/5/162},
  urldate = {2025-03-17},
  abstract = {More precise explanations are needed to better understand why public green spaces are diminishing in cities, leading to the loss of ecosystem services that humans receive from natural systems. This paper is devoted to the incremental change of green spaces—a fate that is largely undetectable by urban residents. The paper elucidates a set of drivers resulting in the subtle loss of urban green spaces and elaborates on the consequences of this for resilience planning of ecosystem services. Incremental changes of greenspace trigger baseline shifts, where each generation of humans tends to take the current condition of an ecosystem as the normal state, disregarding its previous states. Even well-intended political land-use decisions, such as current privatization schemes, can cumulatively result in undesirable societal outcomes, leading to a gradual loss of opportunities for nature experience. Alfred E. Kahn referred to such decision making as ‘the tyranny of small decisions.’ This is mirrored in urban planning as problems that are dealt with in an ad hoc manner with no officially formulated vision for long-term spatial planning. Urban common property systems could provide interim solutions for local governments to survive periods of fiscal shortfalls. Transfer of proprietor rights to civil society groups can enhance the resilience of ecosystem services in cities.},
  issue = {5},
  langid = {english},
  keywords = {baseline shifts,ecosystem services,incremental greenspace loss,privatization,property rights,resilience planning,the tyranny of small decisions,urban densification,urban greenspace,urban nature connection},
  file = {C:\Users\noiri\Zotero\storage\G9RFEKM3\Colding et al. - 2020 - The Incremental Demise of Urban Green Spaces.pdf}
}

@inreference{ControlTheory2025,
  title = {Control Theory},
  booktitle = {Wikipedia},
  date = {2025-03-17T01:00:08Z},
  url = {https://en.wikipedia.org/w/index.php?title=Control_theory&oldid=1280889989},
  urldate = {2025-04-12},
  abstract = {Control theory is a field of control engineering and applied mathematics that deals with the control of dynamical systems in engineered processes and machines. The objective is to develop a model or algorithm governing the application of system inputs to drive the system to a desired state, while minimizing any delay, overshoot, or steady-state error and ensuring a level of control stability; often with the aim to achieve a degree of optimality. To do this, a controller with the requisite corrective behavior is required. This controller monitors the controlled process variable (PV), and compares it with the reference or set point (SP). The difference between actual and desired value of the process variable, called the error signal, or SP-PV error, is applied as feedback to generate a control action to bring the controlled process variable to the same value as the set point. Other aspects which are also studied are  controllability and observability.  Control theory is used in control system engineering to design automation  that have revolutionized manufacturing, aircraft, communications and other industries, and created new fields such as robotics.   Extensive use is usually made of a diagrammatic style known as the block diagram. In it the transfer function, also known as the system function or network function, is a mathematical model of the relation between the input and output based on the differential equations describing the system. Control theory dates from the 19th century, when the theoretical basis for the operation of governors was first described by James Clerk Maxwell.  Control theory was further advanced by Edward Routh in 1874, Charles Sturm and in 1895, Adolf Hurwitz, who all contributed to the establishment of control stability criteria; and from 1922 onwards, the development of PID control theory by Nicolas Minorsky. Although a major application of mathematical control theory is in control systems engineering, which deals with the design of process control systems for industry, other applications range far beyond this. As the general theory of feedback systems, control theory is useful wherever feedback occurs - thus control theory also has applications in life sciences, computer engineering, sociology and operations research.},
  langid = {english},
  annotation = {Page Version ID: 1280889989},
  file = {C:\Users\noiri\Zotero\storage\ZETE2NGK\Control_theory.html}
}

@inproceedings{damianUsingFullyConvolutional2019,
  title = {Using {{Fully Convolutional Networks}} for {{Rumex Obtusifolius Segmentation}}, a {{Preliminary Report}}},
  booktitle = {2019 {{International Symposium ELMAR}}},
  author = {Damian, Schori and Thomas, Anken and Dejan, Šeatović},
  date = {2019-09},
  pages = {119--122},
  issn = {1334-2630},
  doi = {10.1109/ELMAR.2019.8918914},
  url = {https://ieeexplore.ieee.org/document/8918914/?arnumber=8918914},
  urldate = {2024-07-23},
  abstract = {Image segmentation of specific plants is an important task in precision farming. Several influences such as changing light, varying arrangement of leaves and similarly looking plants are challenging. We present a solution for segmenting individual Rumex obtusifolius plants out of complicated natural scenes in grassland from 2D images. We are making use of a fully convolutional deep neural network (FCN) trained with hand labeled images. The proposed segmentation scheme is validated with images taken under outdoor conditions. The overall masks segmentation rate is 84.8\% measured by the dice coefficient. Approximately half of the experiments show segmentation rates of individual plants higher than 88\%. The developed solution is therefore a robust method to segment Rumex obtusifolius plants under real-world conditions in short time.},
  eventtitle = {2019 {{International Symposium ELMAR}}},
  keywords = {Computer Vision,Deep Learning,Image segmentation,Image Segmentation,Object segmentation,Real-time systems,Robots,Robustness,Rumex obtusifolius,Three-dimensional displays,Training},
  file = {C\:\\Users\\noiri\\Zotero\\storage\\N5NJURKD\\Damian et al. - 2019 - Using Fully Convolutional Networks for Rumex Obtus.pdf;C\:\\Users\\noiri\\Zotero\\storage\\3EX4GQ5J\\8918914.html}
}

@article{decroonInsectinspiredAIAutonomous2022,
  title = {Insect-Inspired {{AI}} for Autonomous Robots},
  author = {De Croon, G. C. H. E. and Dupeyroux, J. J. G. and Fuller, S. B. and Marshall, J. A. R.},
  date = {2022-06-29},
  journaltitle = {Science Robotics},
  shortjournal = {Sci. Robot.},
  volume = {7},
  number = {67},
  pages = {eabl6334},
  issn = {2470-9476},
  doi = {10.1126/scirobotics.abl6334},
  url = {https://www.science.org/doi/10.1126/scirobotics.abl6334},
  urldate = {2025-02-25},
  abstract = {Autonomous robots are expected to perform a wide range of sophisticated tasks in complex, unknown environments. However, available onboard computing capabilities and algorithms represent a considerable obstacle to reaching higher levels of autonomy, especially as robots get smaller and the end of Moore’s law approaches. Here, we argue that inspiration from insect intelligence is a promising alternative to classic methods in robotics for the artificial intelligence (AI) needed for the autonomy of small, mobile robots. The advantage of insect intelligence stems from its resource efficiency (or parsimony) especially in terms of power and mass. First, we discuss the main aspects of insect intelligence underlying this parsimony: embodiment, sensory-motor coordination, and swarming. Then, we take stock of where insect-inspired AI stands as an alternative to other approaches to important robotic tasks such as navigation and identify open challenges on the road to its more widespread adoption. Last, we reflect on the types of processors that are suitable for implementing insect-inspired AI, from more traditional ones such as microcontrollers and field-programmable gate arrays to unconventional neuromorphic processors. We argue that even for neuromorphic processors, one should not simply apply existing AI algorithms but exploit insights from natural insect intelligence to get maximally efficient AI for robot autonomy.           ,              We discuss insect-inspired artificial intelligence as the key to autonomous robots with extremely limited computing power.},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\VW6RH829\De Croon et al. - 2022 - Insect-inspired AI for autonomous robots.pdf}
}

@online{dejanHowControlStepper2015,
  title = {How {{To Control}} a {{Stepper Motor}} with {{A4988 Driver}} and {{Arduino}}},
  author = {Dejan},
  date = {2015-08-16T11:01:33+00:00},
  url = {https://howtomechatronics.com/tutorials/arduino/how-to-control-stepper-motor-with-a4988-driver-and-arduino/},
  urldate = {2024-08-23},
  abstract = {In this Arduino Tutorial we will learn how to control a Stepper Motor using the A4988 Stepper Driver. The A4988 is a microstepping driver for controlling bipolar stepper motors which has built-in translator for easy operation. This means that we can control the stepper motor with...},
  langid = {american},
  organization = {How To Mechatronics},
  file = {C:\Users\noiri\Zotero\storage\RIS89YKB\how-to-control-stepper-motor-with-a4988-driver-and-arduino.html}
}

@online{dirkUniversalBuildTool,
  title = {A Universal Build Tool},
  author = {Dirk, Thomas},
  url = {https://design.ros2.org/articles/build_tool.html},
  urldate = {2024-11-19},
  file = {C:\Users\noiri\Zotero\storage\DY2IAG4C\build_tool.html}
}

@software{dockerHowComposeWorks,
  title = {How {{Compose}} Works},
  author = {Docker},
  url = {https://docs.docker.com/compose/intro/compose-application-model/}
}

@software{dockerRosOfficialImage,
  title = {Ros - {{Official Image}} | {{Docker Hub}}},
  author = {Docker},
  url = {https://hub.docker.com/_/ros},
  urldate = {2024-11-18},
  abstract = {The Robot Operating System (ROS) is an open source project for building robot applications.},
  file = {C:\Users\noiri\Zotero\storage\Q25PV4QU\ros.html}
}

@online{DockerSwarmVs,
  title = {Docker {{Swarm}} vs. {{Kubernetes}} - {{Key Differences Explained}}},
  url = {https://spacelift.io/blog/[slug]},
  urldate = {2025-03-25},
  abstract = {Discover the similarities and differences between Docker Swarm and Kubernetes and see which is better for your use case.},
  langid = {english},
  organization = {Spacelift},
  file = {C:\Users\noiri\Zotero\storage\XTC7ZFUV\docker-swarm-vs-kubernetes.html}
}

@software{dockerWhatDocker,
  title = {What Is {{Docker}}?},
  author = {Docker},
  url = {https://docs.docker.com/get-started/docker-overview/}
}

@thesis{dollingerKameragefuehrtePositionierungUnd2014,
  type = {Thesis},
  title = {Kamerageführte Positionierung und Greifbewegung eines Roboterarms},
  author = {Dollinger, Moritz},
  date = {2014-11-13},
  institution = {Hochschule für angewandte Wissenschaften Hamburg},
  url = {https://reposit.haw-hamburg.de/handle/20.500.12738/6774},
  urldate = {2024-03-06},
  abstract = {Ziel dieser Arbeit ist die bildbasierte Detektion und Rekonstruktion der Positionen von  Objekten im 3D-Raum für eine visuelle Steuerung eines Knickarmroboters. Dieser  soll die detektierten Gegenstände anfahren, greifen und der Größe nach sortieren.  Die Aufnahmen des Arbeitsraums des Roboterarms sollen aus verschiedenen  Perspektiven mit Hilfe zweier Kameras gewonnen werden. Durch einen einmaligen  Kalibriervorgang sollen die Positionen und die internen Parameter der verwendeten  Kameras zunächst bestimmt werden. Mit diesen Parametern können dann aus den  2D-Pixelkoordinaten der Objekte und des Greifers des Roboterarms die jeweiligen  Positionen im 3D-Raum rekonstruiert werden. Anschließend soll eine Bahnplanung  für den Greifer unter Verwendung der inversen Kinematik erfolgen, um die einzelnen  Objekte zu bewegen.},
  langid = {ngerman},
  annotation = {Accepted: 2020-09-29T12:46:13Z},
  file = {C:\Users\noiri\Zotero\storage\4NDUGRAC\Dollinger - 2014 - Kamerageführte Positionierung und Greifbewegung ei.pdf}
}

@article{douchaProductivityCO2O22006,
  title = {Productivity, {{CO2}}/{{O2}} Exchange and Hydraulics in Outdoor Open High Density Microalgal ({{Chlorella}} Sp.) Photobioreactors Operated in a {{Middle}} and {{Southern European}} Climate},
  author = {Doucha, J. and Lívanský, K.},
  date = {2006-11-22},
  journaltitle = {Journal of Applied Phycology},
  shortjournal = {J Appl Phycol},
  volume = {18},
  number = {6},
  pages = {811--826},
  issn = {0921-8971, 1573-5176},
  doi = {10.1007/s10811-006-9100-4},
  url = {http://link.springer.com/10.1007/s10811-006-9100-4},
  urldate = {2025-03-14},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\RYCETD78\Doucha und Lívanský - 2006 - Productivity, CO2O2 exchange and hydraulics in outdoor open high density microalgal (Chlorella sp.).pdf}
}

@video{engineeringeducatoracademyImageBasedVisualServoing2021,
  entrysubtype = {video},
  title = {Image-{{Based Visual Servoing}} - {{Robot Control Part}}  1},
  editor = {{Engineering Educator Academy}},
  editortype = {director},
  date = {2021-12-19},
  url = {https://www.youtube.com/watch?v=s_0DdxHjrfA},
  urldate = {2024-03-06},
  abstract = {Basics of computer-vision for image-based control of robotic arms are explained in this video, including the pinhole camera model, perspective projection, intrinsic and extrinsic camera parameters, focal axis and focal length, feature points and feature matching, and difference between position-based visual servo control and image-based visual servo control of robotic arms.}
}

@book{fahimiAutonomousRobotsModeling2009,
  title = {Autonomous {{Robots}}: {{Modeling}}, {{Path Planning}}, and {{Control}}},
  shorttitle = {Autonomous {{Robots}}},
  author = {Fahimi, Farbod},
  date = {2009},
  publisher = {Springer US},
  location = {Boston, MA},
  doi = {10.1007/978-0-387-09538-7},
  url = {https://link.springer.com/10.1007/978-0-387-09538-7},
  urldate = {2024-11-16},
  isbn = {978-0-387-09537-0 978-0-387-09538-7},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\844WU3J3\Fahimi - 2009 - Autonomous Robots Modeling, Path Planning, and Control.pdf}
}

@software{farmbotFarmBotOpenSourceCNC,
  title = {{{FarmBot}} | {{Open-Source CNC Farming}}},
  author = {FarmBot},
  url = {https://farm.bot/},
  urldate = {2024-09-26},
  abstract = {Farming and gardening robots for home, educational, and commercial use. Premium Hardware · Worldwide Shipping · Drag and Drop Farm Designer · Step-by-Step Assembly Instructions · Own Your Food},
  file = {C:\Users\noiri\Zotero\storage\SFXPGFX3\farm.bot.html}
}

@software{farmbotGettingStartedGazebo,
  title = {Getting {{Started}} with {{Gazebo}}? — {{Gazebo}} Harmonic Documentation},
  author = {FarmBot},
  url = {https://gazebosim.org/docs/latest/getstarted/},
  urldate = {2024-09-21},
  file = {C:\Users\noiri\Zotero\storage\QV8PSCHA\getstarted.html}
}

@software{flatscher2btDockerforrobotics2025,
  title = {2b-t/Docker-for-Robotics},
  author = {Flatscher, Tobit},
  date = {2025-03-05T07:29:27Z},
  origdate = {2023-02-05T11:31:22Z},
  url = {https://github.com/2b-t/docker-for-robotics},
  urldate = {2025-03-05},
  abstract = {Collection of best practices for working with Docker/Docker-Compose and the Robot Operating System (ROS/ROS 2) in simulation as well as with hardware and real-time requirements},
  keywords = {best-practice,best-practices,docker,docker-compose,dockerfile,graphic-user-interface,gui,guide,guidelines,network,real-time,robot,robot-operating-system,robotics,ros,ros-noetic,ros2,ros2-humble,tutorial,wsl2}
}

@software{formantGlossaryURDF,
  title = {Glossary | {{URDF}}},
  author = {Formant},
  url = {https://formant.io/resources/glossary/urdf/},
  urldate = {2024-11-14},
  abstract = {URDF provides the information a human operator needs to know to understand the physical shape and size of a robot.},
  file = {C:\Users\noiri\Zotero\storage\DJ9QC8T2\urdf.html}
}

@online{frohlichRos2_control_demosRos2_control_demo_descriptionDiffbot,
  title = {Ros2\_control\_demos/Ros2\_control\_demo\_description/Diffbot/Urdf/Diffbot\_description.Urdf.Xacro at Master · Grahanoi/Ros2\_control\_demos},
  author = {Fröhlich, Christoph},
  url = {https://github.com/grahanoi/ros2_control_demos/blob/master/ros2_control_demo_description/diffbot/urdf/diffbot_description.urdf.xacro},
  urldate = {2024-12-09},
  file = {C:\Users\noiri\Zotero\storage\S6GZITLU\diffbot_description.urdf.html}
}

@software{frohlichRoscontrolsRos2_control_demosThis,
  title = {Ros-Controls/Ros2\_control\_demos: {{This}} Repository Aims at Providing Examples to Illustrate Ros2\_control and Ros2\_controllers},
  author = {Fröhlich, Christoph},
  url = {https://github.com/ros-controls/ros2_control_demos},
  urldate = {2024-12-05}
}

@online{Gazebo,
  title = {Gazebo},
  url = {https://app.gazebosim.org},
  urldate = {2025-03-03},
  abstract = {Web application for Gazebo},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\WN8EZFNU\models.html}
}

@online{GazebosimRos_gzIntegration,
  title = {Gazebosim/Ros\_gz: {{Integration}} between {{ROS}} (1 and 2) and {{Gazebo}} Simulation},
  url = {https://github.com/gazebosim/ros_gz/tree/ros2},
  urldate = {2024-12-05},
  file = {C:\Users\noiri\Zotero\storage\RHIAAU87\ros2.html}
}

@online{GettingStartedImage,
  title = {Getting {{Started}} with {{Image Preprocessing}} in {{Python}}},
  url = {https://kaggle.com/code/rimmelasghar/getting-started-with-image-preprocessing-in-python},
  urldate = {2024-04-22},
  abstract = {Explore and run machine learning code with Kaggle Notebooks | Using data from Animals-10},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\CF8WE6PC\getting-started-with-image-preprocessing-in-python.html}
}

@online{GettingStartedNav2,
  title = {Getting {{Started}} — {{Nav2}} 1.0.0 Documentation},
  url = {https://docs.nav2.org/getting_started/index.html},
  urldate = {2025-04-09},
  file = {C:\Users\noiri\Zotero\storage\NZ2ATWMH\index.html}
}

@inproceedings{gilesDevelopmentFacialRecognition2023,
  title = {Development of a {{Facial Recognition Pantograph Drawing Robot}}},
  booktitle = {2023 3rd {{International Conference}} on {{Robotics}}, {{Electrical}} and {{Signal Processing Techniques}} ({{ICREST}})},
  author = {Giles, Daniel and Glenn, Payton and Burnell, Travis and Flynn, Skylar and Noorani, R.},
  date = {2023-01},
  pages = {62--67},
  doi = {10.1109/ICREST57604.2023.10070086},
  url = {https://ieeexplore.ieee.org/document/10070086},
  urldate = {2025-03-03},
  abstract = {This paper describes the design and application of a solar powered drawing robot that implements face detection, image to sketch conversion, and wireless communication between the robot and the main computer. The robot has the capability to detect and capture a picture of a human face, convert the image to a sketch in the form of a series of lines, and physically draw the image on a whiteboard. Additionally, the robot can draw any selected image stored on the main computer, apply or remove shading from the image, move to a specified location away from the sketch to provide a clear area for the user to erase the board, and can draw diagnostic test rectangles to analyze the mechanical performance of the system. These robotic functions were implemented by first determining the angles and geometry of the arms required to locate a given x-y coordinatepoint. This was done using properties of triangles, as well as the known physical limitations of the pantograph's size. A CAD model of the design was created to incorporate both the calculated geometry and purchased parts, such as the servo motors, axles, and bearings. Existing open-source libraries were used to aid in facial recognition and the conversion of images to a sketch of x-y points. By utilizing the known geometry of the robot, the pen was programmed to move to specified points based on the angles of the two servo motors.},
  eventtitle = {2023 3rd {{International Conference}} on {{Robotics}}, {{Electrical}} and {{Signal Processing Techniques}} ({{ICREST}})},
  keywords = {Face recognition,Geometry,Manipulators,Robot kinematics,Signal processing,Solid modeling,Wireless communication},
  file = {C\:\\Users\\noiri\\Zotero\\storage\\7P3W7X7U\\Giles et al. - 2023 - Development of a Facial Recognition Pantograph Drawing Robot.pdf;C\:\\Users\\noiri\\Zotero\\storage\\NVBK9SGZ\\10070086.html}
}

@inproceedings{gobeeVisionbasedPillBlister2023,
  title = {Vision-Based {{Pill Blister Package Inspection System}} Using {{CNN}}},
  booktitle = {Proceedings of the 2023 13th {{International Conference}} on {{Biomedical Engineering}} and {{Technology}}},
  author = {Gobee, Suresh and Durairajah, Vickneswari and Prea, Laurent Eddie Sylvester},
  date = {2023-12-19},
  series = {{{ICBET}} '23},
  pages = {93--98},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3620679.3620694},
  url = {https://dl.acm.org/doi/10.1145/3620679.3620694},
  urldate = {2024-03-03},
  abstract = {This research aimed to develop an automated blister package sorting system based on defects detected using image data. The proposed approach aims to reduce the lead time incurred by manual sorting in the production environment and provide a low-cost automated alternative. The image detection model to detect the defects was developed using YOLOv5 pre-trained object detection model from the PyTorch framework. The dataset collected 350 labeled images, including 40\% of those which were augmented and duplicated using Roboflow image processing. The object detection results were leveraged in multiple ways including detecting the presence of blister package in the frame and for pose estimation, among the mainstream defect detection. The image coordinate was converted to a robot arm coordinate to enable effective manipulation. Dobot Magician Robot arm was used to actuate the blister package and was controlled using its native API. The image processing and robot arm manipulation module was integrated using Python. The detection model held a mean average precision(mAP) of 86.1\% for any random rotations of the blister package, and the sorting rate averaged 7.68s per iteration..},
  isbn = {979-8-4007-0743-8},
  keywords = {Deep learning,Machine Vision,Pill inspection,Robot arm integration}
}

@software{graciaarandaGazeboddspluginsSrcDiff_drive,
  title = {Gazebo-Dds-Plugins/Src/Diff\_drive/{{README}}.Md at Master · Rticommunity/Gazebo-Dds-Plugins},
  author = {Gracía Aranda, Fernando},
  url = {https://github.com/rticommunity/gazebo-dds-plugins/blob/master/src/diff_drive/README.md},
  urldate = {2024-12-09},
  abstract = {DDS Gazebo Plugins enable DDS-based robotic systems to leverage Gazebo's simulation capabilities, such as 3D simulation and computer vision. - rticommunity/gazebo-dds-plugins},
  file = {C:\Users\noiri\Zotero\storage\424DYE4K\README.html}
}

@misc{grahamDigitalTwinAutonomous2024,
  title = {Digital {{Twin}} for {{Autonomous Robots}} Using {{ROS2}}},
  author = {Graham, Noirin},
  date = {2024-12-11},
  url = {https://github.com/digital-twin-autonomous-farmbot/report/blob/master/report/main.pdf},
  langid = {english}
}

@article{grimmondUrbanizationGlobalEnvironmental2007,
  title = {Urbanization and {{Global Environmental Change}}: {{Local Effects}} of {{Urban Warming}}},
  shorttitle = {Urbanization and {{Global Environmental Change}}},
  author = {Grimmond, Sue},
  date = {2007},
  journaltitle = {The Geographical Journal},
  volume = {173},
  number = {1},
  eprint = {30113496},
  eprinttype = {jstor},
  pages = {83--88},
  publisher = {[Wiley, Royal Geographical Society (with the Institute of British Geographers)]},
  issn = {0016-7398},
  url = {https://www.jstor.org/stable/30113496},
  urldate = {2025-03-17},
  file = {C:\Users\noiri\Zotero\storage\PCDM9X7E\Grimmond - 2007 - Urbanization and Global Environmental Change Local Effects of Urban Warming.pdf}
}

@article{hobbieNaturebasedApproachesManaging2020,
  title = {Nature-Based Approaches to Managing Climate Change Impacts in Cities},
  author = {Hobbie, Sarah E. and Grimm, Nancy B.},
  date = {2020-01-27},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume = {375},
  number = {1794},
  pages = {20190124},
  publisher = {Royal Society},
  doi = {10.1098/rstb.2019.0124},
  url = {https://royalsocietypublishing.org/doi/full/10.1098/rstb.2019.0124},
  urldate = {2025-03-17},
  abstract = {Managing and adapting to climate change in urban areas will become increasingly important as urban populations grow, especially because unique features of cities amplify climate change impacts. High impervious cover exacerbates impacts of climate warming through urban heat island effects and of heavy rainfall by magnifying runoff and flooding. Concentration of human settlements along rivers and coastal zones increases exposure of people and infrastructure to climate change hazards, often disproportionately affecting those who are least prepared. Nature-based strategies (NBS), which use living organisms, soils and sediments, and/or landscape features to reduce climate change hazards, hold promise as being more flexible, multi-functional and adaptable to an uncertain and non-stationary climate future than traditional approaches. Nevertheless, future research should address the effectiveness of NBS for reducing climate change impacts and whether they can be implemented at scales appropriate to climate change hazards and impacts. Further, there is a need for accurate and comprehensive cost–benefit analyses that consider disservices and co-benefits, relative to grey alternatives, and how costs and benefits are distributed across different communities. NBS are most likely to be effective and fair when they match the scale of the challenge, are implemented with input from diverse voices and are appropriate to specific social, cultural, ecological and technological contexts. This article is part of the theme issue ‘Climate change and ecosystems: threats, opportunities and solutions’.},
  keywords = {cities,climate change adaptation,green infrastructure,nature-based strategies,urban ecosystems},
  file = {C:\Users\noiri\Zotero\storage\RCDHTAS2\Hobbie und Grimm - 2020 - Nature-based approaches to managing climate change impacts in cities.pdf}
}

@online{Images,
  title = {Images},
  url = {https://kubernetes.io/docs/concepts/containers/images/},
  urldate = {2025-03-05},
  abstract = {A container image represents binary data that encapsulates an application and all its software dependencies. Container images are executable software bundles that can run standalone and that make very well defined assumptions about their runtime environment. You typically create a container image of your application and push it to a registry before referring to it in a Pod. This page provides an outline of the container image concept. Note:If you are looking for the container images for a Kubernetes release (such as v1.},
  langid = {english},
  organization = {Kubernetes},
  file = {C:\Users\noiri\Zotero\storage\92J9R737\images.html}
}

@misc{indriAMRSystemAutonomous,
  title = {{{AMR}} System for Autonomous Indoor Navigation in Unknown Environments},
  author = {Indri, Marina},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\7JA6HL33\Indri - AMR system for autonomous indoor navigation in unknown environments.pdf}
}

@online{IndustrialRevolution2025,
  title = {Industrial Revolution},
  date = {2025-03-12},
  url = {https://dictionary.cambridge.org/de/worterbuch/englisch/industrial-revolution},
  urldate = {2025-03-17},
  abstract = {1. the period of time during which work began to be done more by machines in…},
  langid = {ngerman},
  file = {C:\Users\noiri\Zotero\storage\C3HW79PV\industrial-revolution.html}
}

@online{InstallingGazeboROS,
  title = {Installing {{Gazebo}} with {{ROS}} — {{Gazebo}} Harmonic Documentation},
  url = {https://gazebosim.org/docs/harmonic/ros_installation/#summary-of-compatible-ros-and-gazebo-combinations},
  urldate = {2024-09-20},
  file = {C:\Users\noiri\Zotero\storage\9ATSTMZZ\ros_installation.html}
}

@online{InstallingGazeboROSa,
  title = {Installing {{Gazebo}} with {{ROS}} — {{Gazebo}} Harmonic Documentation},
  url = {https://gazebosim.org/docs/harmonic/ros_installation/#summary-of-compatible-ros-and-gazebo-combinations},
  urldate = {2024-11-03},
  file = {C:\Users\noiri\Zotero\storage\J67VZ2VA\ros_installation.html}
}

@book{jefferiesRoboticsCognitiveApproaches2008,
  title = {Robotics and Cognitive Approaches to Spatial Mapping},
  editor = {Jefferies, Margaret E. and Yeap, Wai K.},
  date = {2008},
  series = {Springer Tracts in Advanced Robotics},
  number = {v. 38},
  publisher = {Springer},
  location = {Berlin ; New York},
  isbn = {978-3-540-75386-5},
  pagetotal = {328},
  keywords = {Robotics,Space perception},
  annotation = {OCLC: ocn173721135}
}

@inproceedings{jessenSolarPoweredGrass2023,
  title = {Solar {{Powered Grass Cutter}} with {{Obstacle Avoidance Function Using IoT}}},
  booktitle = {2023 {{International Conference}} on {{Intelligent Sensing}} and {{Industrial Automation}}},
  author = {Jessen, Wong and Tahir, Ir Noor Idayu Binti Mohd and Khan, M.K.A. Ahamed},
  date = {2023-12-09},
  pages = {1--7},
  publisher = {ACM},
  location = {Virtual Event China},
  doi = {10.1145/3632314.3632360},
  url = {https://dl.acm.org/doi/10.1145/3632314.3632360},
  urldate = {2025-03-24},
  eventtitle = {{{ISIA}} 2023: 2023 {{International Conference}} on {{Intelligent Sensing}} and {{Industrial Automation}}},
  isbn = {979-8-4007-0940-1},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\2RZYHMKX\Jessen et al. - 2023 - Solar Powered Grass Cutter with Obstacle Avoidance Function Using IoT.pdf}
}

@inproceedings{jiaControlStrategySimulation2024,
  title = {A {{Control Strategy}} and {{Simulation}} for {{Precision Control}} of {{Robot Arms}}},
  booktitle = {Proceedings of the 2024 4th {{International Conference}} on {{Control}} and {{Intelligent Robotics}}},
  author = {Jia, Wenqi and Wang, Jihong},
  date = {2024-06-21},
  pages = {207--211},
  publisher = {ACM},
  location = {Guangzhou China},
  doi = {10.1145/3687488.3687525},
  url = {https://dl.acm.org/doi/10.1145/3687488.3687525},
  urldate = {2025-03-03},
  eventtitle = {{{ICCIR}} 2024: 2024 4th {{International Conference}} on {{Control}} and {{Intelligent Robotics}}},
  isbn = {979-8-4007-0993-7},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\LKDGPNJX\Jia und Wang - 2024 - A Control Strategy and Simulation for Precision Control of Robot Arms.pdf}
}

@online{JoshnewansArticubot_one,
  title = {Joshnewans/Articubot\_one},
  url = {https://github.com/joshnewans/articubot_one},
  urldate = {2024-12-05}
}

@online{JoshnewansMy_botTemplate,
  title = {Joshnewans/My\_bot: {{Template}} for a {{ROS}} Package},
  url = {https://github.com/joshnewans/my_bot},
  urldate = {2024-12-05}
}

@online{JoshnewansSerial_motor_demo,
  title = {Joshnewans/Serial\_motor\_demo},
  url = {https://github.com/joshnewans/serial_motor_demo},
  urldate = {2024-12-05},
  file = {C:\Users\noiri\Zotero\storage\C7L4P694\serial_motor_demo.html}
}

@article{kamRVizToolkitReal2015,
  title = {{{RViz}}: A Toolkit for Real Domain Data Visualization},
  shorttitle = {{{RViz}}},
  author = {Kam, Hyeong Ryeol and Lee, Sung-Ho and Park, Taejung and Kim, Chang-Hun},
  date = {2015-10},
  journaltitle = {Telecommunication Systems},
  shortjournal = {Telecommun Syst},
  volume = {60},
  number = {2},
  pages = {337--345},
  issn = {1018-4864, 1572-9451},
  doi = {10.1007/s11235-015-0034-5},
  url = {http://link.springer.com/10.1007/s11235-015-0034-5},
  urldate = {2024-11-16},
  langid = {english}
}

@article{latschOptimisationHotwaterApplication2014,
  title = {Optimisation of Hot-Water Application Technology for the Control of Broad-Leaved Dock ({{Rumex}} Obtusifolius)},
  author = {Latsch, Roy and Sauter, Joachim},
  date = {2014-12-21},
  journaltitle = {Journal of Agricultural Engineering},
  volume = {45},
  number = {4},
  pages = {137--145},
  issn = {2239-6268},
  doi = {10.4081/jae.2014.239},
  url = {https://www.agroengineering.org/jae/article/view/jae.2014.239},
  urldate = {2024-07-23},
  abstract = {In organic farming, the control of broad-leaved dock (Rumex obtusifolius) via hot-water treatment of the upper root region (hypocotyl) is a new alternative to the current standard control method involving manual digging-out of the roots. This comparative study looks at five different hot-water application techniques. The aim is to optimise the control method in terms of water and energy requirement to obtain a mortality rate of the treated plants of at least 80\%. The studied parameters were the application, the amount of water, the water temperature, the soil moisture content and the soil type. In total, 813 plants of varying size were treated (120-225 plants per treatment). The success of each treatment was rated 12 weeks after it was applied. Based on the results, the preferred treatment in terms of water and energy requirement was a commercially available rotary nozzle. With this nozzle, for example, at 40 vol.-\% soil moisture, 1.6 L of water at a temperature of 90Â°C was necessary for successful Rumex control. The rotary nozzle could be used as a non-contact system, and was therefore the most user-friendly of the application techniques examined.},
  issue = {4},
  langid = {english},
  keywords = {broad-leaved dock,organic farming.,Rumex obtusifolius,thermal treatment,weed control},
  file = {C:\Users\noiri\Zotero\storage\L7C7U679\Latsch und Sauter - 2014 - Optimisation of hot-water application technology f.pdf}
}

@inproceedings{leDigitalTwinApproach2024,
  title = {Digital Twin Approach for Machining with Robotic Manipulator},
  booktitle = {Proceedings of the 2024 {{International Conference}} on {{Advanced Robotics}}, {{Automation Engineering}} and {{Machine Learning}}},
  author = {Le, Van and Mao, Xuanyu and Tran, Minh and Ding, Songlin},
  date = {2024-06-28},
  pages = {12--17},
  publisher = {ACM},
  location = {Hangzhou China},
  doi = {10.1145/3677454.3677457},
  url = {https://dl.acm.org/doi/10.1145/3677454.3677457},
  urldate = {2024-09-18},
  eventtitle = {{{ARAEML}} 2024: 2024 {{International Conference}} on {{Advanced Robotics}}, {{Automation Engineering}} and {{Machine Learning}}},
  isbn = {979-8-4007-1711-6},
  langid = {english}
}

@inproceedings{liuPerformanceValidationYolo2021,
  title = {Performance {{Validation}} of {{Yolo Variants}} for {{Object Detection}}},
  booktitle = {Proceedings of the 2021 {{International Conference}} on {{Bioinformatics}} and {{Intelligent Computing}}},
  author = {Liu, Kaiyue and Tang, Haitong and He, Shuang and Yu, Qin and Xiong, Yulong and Wang, Nizhuan},
  date = {2021-03-21},
  series = {{{BIC}} 2021},
  pages = {239--243},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3448748.3448786},
  url = {https://dl.acm.org/doi/10.1145/3448748.3448786},
  urldate = {2024-03-04},
  abstract = {Object detection is a core part of an intelligent surveillance system and a fundamental algorithm in the field of identity identification, which is of great practical importance. Since the YOLO series algorithms have good results in terms of accuracy and speed, YOLO and each subsequent version have been surpassing. Thus, in this paper, it carries out experiments on three versions of popular YOLO models such as yolov3, yolov4, and yolov5 (yolov5l, yolov5m, yolov5s, yolov5x). The performance of the three versions of YOLO model is analyzed and summarized by training and predicting the public VOC dataset. Results showed that the yolov4 model is higher than the yolov3 model in terms of mAP values, but slightly lower in terms of speed, while the yolov5 series model is better than the yolov3 and yolov4 models both in terms of mAP values and speed.},
  isbn = {978-1-4503-9000-2},
  keywords = {Deep Learning,Object Detection,PASCAL VOC Dataset,YOLO},
  file = {C:\Users\noiri\Zotero\storage\29WYQF8T\Liu et al. - 2021 - Performance Validation of Yolo Variants for Object.pdf}
}

@inproceedings{luoVisionbased3objectPickplace2017,
  title = {Vision-Based 3-{{D}} Object Pick-and-Place Tasks of Industrial Manipulator},
  booktitle = {2017 {{International Automatic Control Conference}} ({{CACS}})},
  author = {Luo, Guor-Yieh and Cheng, Ming-Yang and Chiang, Chia-Ling},
  date = {2017-11},
  pages = {1--7},
  doi = {10.1109/CACS.2017.8284250},
  url = {https://ieeexplore.ieee.org/abstract/document/8284250},
  urldate = {2024-03-03},
  abstract = {When dealing with complicated tasks such as object pick-and-place, it is harder for robotic arms alone to complete them. One of the possible solutions to overcoming the aforementioned difficulties is to introduce machine vision into the robotic arm system. In this paper, the eye-to-hand camera configuration is adopted in the development of the vision-based automatic pick-and-place systems for 3-D objects. The vision-based automatic pick-and-place system developed in this paper consists of three main sections - calibration of machine vision system, object recognition, and transformations of object coordinates. Experimental results indicate that the vision-based automatic pick-and-place system developed in this paper is able to perform an automatic pick-and-place task for 3-D objects.},
  eventtitle = {2017 {{International Automatic Control Conference}} ({{CACS}})},
  keywords = {Calibration,Cameras,Machine vision,Manipulators,Object recognition,Objection recognition,Robot kinematics,Robot vision systems,Stereo vision},
  file = {C\:\\Users\\noiri\\Zotero\\storage\\2DDJPEXL\\Luo et al. - 2017 - Vision-based 3-D object pick-and-place tasks of in.pdf;C\:\\Users\\noiri\\Zotero\\storage\\HMWKDSGC\\8284250.html}
}

@online{macedon971MobileRobotMoving2023,
  type = {Forum post},
  title = {Mobile Robot Moving around Can Not Visualise in {{RVIZ}}, Why So?},
  author = {Macedon971},
  date = {2023-12-29},
  url = {https://stackoverflow.com/q/77730420},
  urldate = {2024-12-05},
  organization = {Stack Overflow}
}

@article{macenskiRobotOperatingSystem2022,
  title = {Robot {{Operating System}} 2: {{Design}}, Architecture, and Uses in the Wild},
  shorttitle = {Robot {{Operating System}} 2},
  author = {Macenski, Steven and Foote, Tully and Gerkey, Brian and Lalancette, Chris and Woodall, William},
  date = {2022-05-25},
  journaltitle = {Science Robotics},
  shortjournal = {Sci. Robot.},
  volume = {7},
  number = {66},
  pages = {eabm6074},
  issn = {2470-9476},
  doi = {10.1126/scirobotics.abm6074},
  url = {https://www.science.org/doi/10.1126/scirobotics.abm6074},
  urldate = {2024-11-14},
  abstract = {The next chapter of the robotics revolution is well underway with the deployment of robots for a broad range of commercial use cases. Even in a myriad of applications and environments, there exists a common vocabulary of components that robots share—the need for a modular, scalable, and reliable architecture; sensing; planning; mobility; and autonomy. The Robot Operating System (ROS) was an integral part of the last chapter, demonstrably expediting robotics research with freely available components and a modular framework. However, ROS 1 was not designed with many necessary production-grade features and algorithms. ROS 2 and its related projects have been redesigned from the ground up to meet the challenges set forth by modern robotic systems in new and exploratory domains at all scales. In this Review, we highlight the philosophical and architectural changes of ROS 2 powering this new chapter in the robotics revolution. We also show through case studies the influence ROS 2 and its adoption has had on accelerating real robot systems to reliable deployment in an assortment of challenging environments.           ,              This Review describes ROS 2’s design, features, and performance with four case studies on land, air, sea, and even space.},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\LQI9DFWT\Macenski et al. - 2022 - Robot Operating System 2 Design, architecture, and uses in the wild.pdf}
}

@article{macenskiSLAMToolboxSLAM2021,
  title = {{{SLAM Toolbox}}: {{SLAM}} for the Dynamic World},
  shorttitle = {{{SLAM Toolbox}}},
  author = {Macenski, Steve and Jambrecic, Ivona},
  date = {2021-05-13},
  journaltitle = {Journal of Open Source Software},
  shortjournal = {JOSS},
  volume = {6},
  number = {61},
  pages = {2783},
  issn = {2475-9066},
  doi = {10.21105/joss.02783},
  url = {https://joss.theoj.org/papers/10.21105/joss.02783},
  urldate = {2025-04-09},
  file = {C:\Users\noiri\Zotero\storage\YN5ILH7D\Macenski und Jambrecic - 2021 - SLAM Toolbox SLAM for the dynamic world.pdf}
}

@video{magicmarksKinematicChainTheory2021,
  entrysubtype = {video},
  title = {Kinematic {{Chain}} | {{Theory}} of {{Machines}}},
  editor = {{Magic Marks}},
  editortype = {director},
  date = {2021-07-20},
  url = {https://www.youtube.com/watch?v=gaj_cuZvHg0},
  urldate = {2025-03-03}
}

@online{ManufactureDeodorantAntiperspirant,
  title = {Manufacture of {{Deodorant}} and {{Antiperspirant}} - {{US}}},
  url = {https://www.silverson.com/us/resource-library/application-reports/manufacture-of-deodorants-and-antiperspirants},
  urldate = {2024-10-29},
  file = {C:\Users\noiri\Zotero\storage\Q74QJIKR\manufacture-of-deodorants-and-antiperspirants.html}
}

@inproceedings{maruyamaExploringPerformanceROS22016,
  title = {Exploring the Performance of {{ROS2}}},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Embedded Software}}},
  author = {Maruyama, Yuya and Kato, Shinpei and Azumi, Takuya},
  date = {2016-10},
  pages = {1--10},
  publisher = {ACM},
  location = {Pittsburgh Pennsylvania},
  doi = {10.1145/2968478.2968502},
  url = {https://dl.acm.org/doi/10.1145/2968478.2968502},
  urldate = {2024-11-18},
  eventtitle = {{{ESWEEK}}'16: {{TWELFTH EMBEDDED SYSTEM WEEK}}},
  isbn = {978-1-4503-4485-2},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\L6HDSX6E\Maruyama et al. - 2016 - Exploring the performance of ROS2.pdf}
}

@online{microsoftWasIstWindowsSubsystem2023,
  title = {Was ist das Windows-Subsystem für Linux?},
  author = {Microsoft},
  date = {2023-12-05},
  url = {https://learn.microsoft.com/de-de/windows/wsl/about},
  urldate = {2024-12-11},
  abstract = {Erfahren Sie mehr über das Windows-Subsystem für Linux einschließlich der verschiedenen Versionen und Einsatzmöglichkeiten. Microsoft liebt Linux.},
  langid = {ngerman},
  file = {C:\Users\noiri\Zotero\storage\HZPLY4JX\about.html}
}

@online{mobilaneDNAInsectScanFuer,
  title = {DNA InsectScan für grüne Fassaden},
  author = {Mobilane},
  url = {https://mobilane.com/de/dna-insect-scan/},
  urldate = {2025-03-10},
  abstract = {DNA InsectScan: Eine neue und einzigartige innovative Methode, um die Wirksamkeit von grünen Fassaden auf die biologische Vielfalt zu messen.},
  langid = {ngerman},
  organization = {Mobilane},
  file = {C:\Users\noiri\Zotero\storage\FW3JFXYW\dna-insect-scan.html}
}

@online{newansDescribingRobotsURDF,
  type = {Tutorial},
  title = {Describing Robots with {{URDF}} | {{Articulated Robotics}}},
  author = {Newans, Josh},
  url = {https://articulatedrobotics.xyz/tutorials/ready-for-ros/urdf},
  urldate = {2024-11-19},
  abstract = {How would you describe a robot? With URDF of course!},
  langid = {english},
  organization = {Articulated Robotics},
  file = {C:\Users\noiri\Zotero\storage\C5BAS53D\urdf.html}
}

@software{newansJoshnewansRos_arduino_bridgeROS,
  title = {Joshnewans/Ros\_arduino\_bridge: {{ROS}} + {{Arduino}} = {{Robot}}},
  author = {Newans, Josh},
  url = {https://github.com/joshnewans/ros_arduino_bridge},
  urldate = {2024-12-05}
}

@online{newansURDFDesignArticulated,
  title = {{{URDF Design}} | {{Articulated Robotics}}},
  author = {Newans, Josh},
  url = {https://articulatedrobotics.xyz/tutorials/mobile-robot/concept-design/concept-urdf},
  urldate = {2024-12-05},
  abstract = {Creating a rough 3D design with URDF},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\PIU49E92\concept-urdf.html}
}

@article{ngocEfficientEvaluationSLAM2023,
  title = {Efficient {{Evaluation}} of {{SLAM Methods}} and {{Integration}} of {{Human Detection}} with {{YOLO Based}} on {{Multiple Optimization}} in {{ROS2}}},
  author = {Ngoc, Hoang Tran and Vinh, Nghi Nguyen and Nguyen, Nguyen Trung and Quach, Luyl-Da},
  date = {2023},
  journaltitle = {International Journal of Advanced Computer Science and Applications},
  shortjournal = {IJACSA},
  volume = {14},
  number = {11},
  issn = {21565570, 2158107X},
  doi = {10.14569/IJACSA.2023.0141130},
  url = {http://thesai.org/Publications/ViewPaper?Volume=14&Issue=11&Code=IJACSA&SerialNo=30},
  urldate = {2025-03-03},
  abstract = {In the realm of robotics, indoor robotics is an increasingly prominent field, and enhancing robot performance stands out as a crucial concern. This research undertakes a comparative analysis of various Simultaneous Localization and Mapping (SLAM) algorithms with the overarching objective of augmenting the navigational capabilities of robots. This is accomplished within an open-source framework known as the Robotic Operating System (ROS2) in conjunction with additional software components such as RVIZ and Gazebo. The central aim of this study is to identify the most efficient SLAM approach by evaluating map accuracy and the time it takes for a robot model to reach its destinations when employing three distinct SLAM algorithms: GMapping, Cartographer SLAM, and SLAM\_toolbox. Furthermore, this study addresses indoor human detection and tracking assignments, in which we evaluate the effectiveness of YOLOv5, YOLOv6, YOLOv7, and YOLOv8 models in conjunction with various optimization algorithms, including SGD, AdamW, and AMSGrad. The study concludes that YOLOv8 with SGD optimization yields the most favorable outcomes for human detection. These proposed systems are rigorously validated through experimentation, utilizing a simulated Gazebo environment within the Robot Operating System 2 (ROS2).},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\KFARPKDI\Ngoc et al. - 2023 - Efficient Evaluation of SLAM Methods and Integration of Human Detection with YOLO Based on Multiple.pdf}
}

@online{OpenContainerInitiative,
  title = {About the {{Open Container Initiative}} - {{Open Container Initiative}}},
  url = {https://opencontainers.org/about/overview/},
  urldate = {2025-03-12},
  file = {C:\Users\noiri\Zotero\storage\R6QML7XL\overview.html}
}

@software{openroboticsBinaryInstallationUbuntu,
  title = {Binary {{Installation}} on {{Ubuntu}} — {{Gazebo}} Ionic Documentation},
  author = {Open Robotics},
  url = {https://gazebosim.org/docs/latest/install_ubuntu/},
  urldate = {2024-11-03},
  file = {C:\Users\noiri\Zotero\storage\6WAG8TI9\install_ubuntu.html}
}

@software{openroboticsCreatingLaunchFile,
  title = {Creating a Launch File — {{ROS}} 2 {{Documentation}}: {{Rolling}} Documentation},
  author = {Open Robotics},
  url = {https://docs.ros.org/en/rolling/Tutorials/Intermediate/Launch/Creating-Launch-Files.html},
  urldate = {2024-11-19},
  file = {C:\Users\noiri\Zotero\storage\J7VW3X83\Creating-Launch-Files.html}
}

@software{openroboticsDistributionsROS2,
  title = {Distributions — {{ROS}} 2 {{Documentation}}: {{Rolling}} Documentation},
  author = {Open Robotics},
  url = {https://docs.ros.org/en/rolling/Releases.html},
  urldate = {2024-11-09},
  file = {C:\Users\noiri\Zotero\storage\F5KQZ89P\Releases.html}
}

@software{openroboticsDistributionsROS2a,
  title = {Distributions — {{ROS}} 2 {{Documentation}}: {{Rolling}} Documentation},
  author = {Open Robotics},
  url = {https://docs.ros.org/en/rolling/Releases.html},
  urldate = {2024-11-13},
  file = {C:\Users\noiri\Zotero\storage\7F8A2VEL\Releases.html}
}

@software{openroboticsGazebo,
  title = {About -- {{Gazebo}}},
  author = {Open Robotics},
  url = {https://gazebosim.org/about},
  urldate = {2024-11-16},
  file = {C:\Users\noiri\Zotero\storage\YSQZ8DMU\about.html}
}

@software{openroboticsJazzyJaliscoJazzy,
  title = {Jazzy {{Jalisco}} (Jazzy) — {{ROS}} 2 {{Documentation}}: {{Jazzy}} Documentation},
  author = {Open Robotics},
  url = {https://docs.ros.org/en/jazzy/Releases/Release-Jazzy-Jalisco.html},
  urldate = {2024-11-09},
  file = {C:\Users\noiri\Zotero\storage\54MDS7UC\Release-Jazzy-Jalisco.html}
}

@software{openroboticsROSHome,
  title = {{{ROS}}: {{Home}}},
  author = {Open Robotics},
  url = {https://www.ros.org/},
  urldate = {2024-08-14},
  file = {C:\Users\noiri\Zotero\storage\MF7NDGAH\www.ros.org.html}
}

@software{openroboticsRvizROSWiki,
  title = {Rviz - {{ROS Wiki}}},
  author = {Open Robotics},
  url = {https://wiki.ros.org/rviz},
  urldate = {2024-11-13},
  file = {C:\Users\noiri\Zotero\storage\VXMP55JD\rviz.html}
}

@software{openroboticsSpawnURDFGazebo,
  title = {Spawn {{URDF}} — {{Gazebo}} Ionic Documentation},
  author = {Open Robotics},
  url = {https://gazebosim.org/docs/latest/spawn_urdf/},
  urldate = {2024-11-11},
  file = {C:\Users\noiri\Zotero\storage\FI9DDUM5\spawn_urdf.html}
}

@software{openroboticsUnderstandingNodesROS,
  title = {Understanding Nodes — {{ROS}} 2 {{Documentation}}: {{Rolling}} Documentation},
  author = {Open Robotics},
  url = {https://docs.ros.org/en/rolling/Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Nodes/Understanding-ROS2-Nodes.html},
  urldate = {2024-12-10},
  file = {C:\Users\noiri\Zotero\storage\8PM2TWQG\Understanding-ROS2-Nodes.html}
}

@software{openroboticsUrdfROSWiki,
  title = {Urdf - {{ROS Wiki}}},
  author = {Open Robotics},
  url = {https://wiki.ros.org/urdf},
  urldate = {2024-11-14},
  file = {C:\Users\noiri\Zotero\storage\3SCMW53K\urdf.html}
}

@software{openroboticsUrdfXMLJoint,
  title = {Urdf/{{XML}}/Joint - {{ROS Wiki}}},
  author = {Open Robotics},
  url = {https://wiki.ros.org/urdf/XML/joint},
  urldate = {2024-11-19},
  file = {C:\Users\noiri\Zotero\storage\U3Z96DCG\joint.html}
}

@software{openroboticsUsingColconBuild,
  title = {Using Colcon to Build Packages — {{ROS}} 2 {{Documentation}}: {{Rolling}} Documentation},
  author = {Open Robotics},
  url = {https://docs.ros.org/en/rolling/Tutorials/Beginner-Client-Libraries/Colcon-Tutorial.html},
  urldate = {2024-11-19},
  file = {C:\Users\noiri\Zotero\storage\V7JWMRIA\Colcon-Tutorial.html}
}

@software{openRunningROS2,
  title = {Running {{ROS}} 2 Nodes in {{Docker}} [Community-Contributed] — {{ROS}} 2 {{Documentation}}: {{Rolling}} Documentation},
  author = {Open, Robotics},
  url = {https://docs.ros.org/en/rolling/How-To-Guides/Run-2-nodes-in-single-or-separate-docker-containers.html},
  urldate = {2024-11-18},
  file = {C:\Users\noiri\Zotero\storage\T4M9NLW4\Run-2-nodes-in-single-or-separate-docker-containers.html}
}

@online{opensourceroboticsfoundationGazeboTutorialGazebo,
  title = {Gazebo : {{Tutorial}} : {{Gazebo}} Plugins in {{ROS}}},
  author = {Open Source Robotics Foundation},
  url = {https://classic.gazebosim.org/tutorials?tut=ros_gzplugins},
  urldate = {2024-12-09},
  file = {C:\Users\noiri\Zotero\storage\N465W6HJ\tutorials.html}
}

@software{opensourceroboticsfoundationSDFormatHome,
  title = {{{SDFormat Home}}},
  author = {Open Source Robotics Foundation},
  url = {http://sdformat.org/},
  urldate = {2024-09-30},
  file = {C:\Users\noiri\Zotero\storage\2QMHYAQR\sdformat.org.html}
}

@online{Overview,
  title = {Overview},
  url = {https://kubernetes.io/docs/concepts/overview/},
  urldate = {2025-03-25},
  abstract = {Kubernetes is a portable, extensible, open source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation. It has a large, rapidly growing ecosystem. Kubernetes services, support, and tools are widely available.},
  langid = {english},
  organization = {Kubernetes},
  file = {C:\Users\noiri\Zotero\storage\BZDHBXWP\overview.html}
}

@online{OverviewArticulatedRobotics,
  title = {Overview | {{Articulated Robotics}}},
  url = {https://articulatedrobotics.xyz/tutorials/},
  urldate = {2024-12-05},
  abstract = {Here are some tutorials!},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\PEF6RLNH\tutorials.html}
}

@misc{pallecchiVisualLocationContext2024,
  title = {Visual Location and Context Recognition of Laboratory Robots},
  author = {Pallecchi, Gianmaria and Gurova, Mariia and Graham, Noirin},
  date = {2024-05-23},
  langid = {english}
}

@online{PIDControllerROS2_Control,
  title = {{{PID Controller}} — {{ROS2}}\_{{Control}}: {{Rolling Mar}} 2025 Documentation},
  url = {https://control.ros.org/rolling/doc/ros2_controllers/pid_controller/doc/userdoc.html},
  urldate = {2025-03-03},
  file = {C:\Users\noiri\Zotero\storage\2ANSYN4M\userdoc.html}
}

@online{PrometheusNodeExporter2020,
  title = {Prometheus Node Exporter on {{Raspberry Pi}} - {{How}} to Install},
  date = {2020-01-17T05:21:21+00:00},
  url = {https://linuxhit.com/prometheus-node-exporter-on-raspberry-pi-how-to-install/},
  urldate = {2025-03-27},
  abstract = {Node exporter is a great way to monitor your Raspberry Pi with Prometheus. Follow these steps to get node exporter running on your Raspberry Pi.},
  langid = {american},
  organization = {Linuxhit},
  file = {C:\Users\noiri\Zotero\storage\M2B7JZG7\prometheus-node-exporter-on-raspberry-pi-how-to-install.html}
}

@article{qiuFieldEstimationMaize2022,
  title = {Field Estimation of Maize Plant Height at Jointing Stage Using an {{RGB-D}} Camera},
  author = {Qiu, Ruicheng and Zhang, Man and He, Yong},
  date = {2022-10-01},
  journaltitle = {The Crop Journal},
  shortjournal = {The Crop Journal},
  series = {Crop Phenotyping Studies with Application to Crop Monitoring},
  volume = {10},
  number = {5},
  pages = {1274--1283},
  issn = {2214-5141},
  doi = {10.1016/j.cj.2022.07.010},
  url = {https://www.sciencedirect.com/science/article/pii/S2214514122001805},
  urldate = {2025-03-03},
  abstract = {Plant height can be used for assessing plant vigor and predicting biomass and yield. Manual measurement of plant height is time-consuming and labor-intensive. We describe a method for measuring maize plant height using an RGB-D camera that captures a color image and depth information of plants under field conditions. The color image was first processed to locate its central area using the S component in HSV color space and the Density-Based Spatial Clustering of Applications with Noise algorithm. Testing showed that the central areas of plants could be accurately located. The point cloud data were then clustered and the plant was extracted based on the located central area. The point cloud data were further processed to generate skeletons, whose end points were detected and used to extract the highest points of the central leaves. Finally, the height differences between the ground and the highest points of the central leaves were calculated to determine plant heights. The coefficients of determination for plant heights manually measured and estimated by the proposed approach were all greater than 0.95. The method can effectively extract the plant from overlapping leaves and estimate its plant height. The proposed method may facilitate maize height measurement and monitoring under field conditions.},
  keywords = {Image processing,Kinect,Maize central area,Maize plant height,Point cloud data},
  file = {C:\Users\noiri\Zotero\storage\KWICGDY6\S2214514122001805.html}
}

@inproceedings{ramisettiAutomaticGrassCutting2024,
  title = {Automatic {{Grass Cutting Robot Using Arduino And Ultrasonic Sensor}}},
  booktitle = {2024 11th {{International Conference}} on {{Reliability}}, {{Infocom Technologies}} and {{Optimization}} ({{Trends}} and {{Future Directions}}) ({{ICRITO}})},
  author = {Ramisetti, Vasanthi and Chowdary, P.Sushma and Bankuru, Chandu and Peda, Sudeepthi and Pasala, Mahendra},
  date = {2024-03},
  pages = {1--4},
  issn = {2769-2884},
  doi = {10.1109/ICRITO61523.2024.10522393},
  url = {https://ieeexplore.ieee.org/document/10522393},
  urldate = {2025-02-28},
  abstract = {In previous times, the task of cutting or mowing grass required a significant amount of time and exertion. The introduction of a novel breed of mowing equipment significantly facilitated the task, however it remains a laborious and time-intensive activity that necessitates oversight. Individuals may personally mow the tiny lawns of their residences, however larger lawns require labor assistance. Regardless of the scenario, the task necessitates an investment of time, effort, or finances. An automatic lawn mower is the solution to this problem. It reduces the amount of time, effort, and labor expenses required. The operation of this machine is governed by an Arduino, which receives input from several sensors and regulates the movement and mowing procedures.In this robotic project, we will build an automatic grass cutter robot or a lawn mower robot using Arduino. The robot can cut the excess grass in the garden automatically. If there is an obstacle in the garden, then it will automatically change its direction. It helps to reduce human efforts. The Automatic Grass Cutting Robot is a modern solution to the labor-intensive task of maintaining lawns and grassy areas. This project aims to design and develop a robot capable of autonomously mowing grass within a predefined area using an Arduino microcontroller and an ultrasonic sensor. The robot's primary function is to navigate the designated area, detect obstacles, and efficiently cut grass using a rotary blade.},
  eventtitle = {2024 11th {{International Conference}} on {{Reliability}}, {{Infocom Technologies}} and {{Optimization}} ({{Trends}} and {{Future Directions}}) ({{ICRITO}})},
  keywords = {Acoustics,Arduino,electric components,LawnMoter,Market research,Microcontrollers,Navigation,Reliability,Robot sensing systems,Sensors},
  file = {C:\Users\noiri\Zotero\storage\ZH9SMNXV\10522393.html}
}

@article{redmonYOLOv3IncrementalImprovement,
  title = {{{YOLOv3}}: {{An Incremental Improvement}}},
  author = {Redmon, Joseph and Farhadi, Ali},
  abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that’s pretty swell. It’s a little bigger than last time but more accurate. It’s still fast though, don’t worry. At 320 × 320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 AP50 in 51 ms on a Titan X, compared to 57.5 AP50 in 198 ms by RetinaNet, similar performance but 3.8× faster. As always, all the code is online at https://pjreddie.com/yolo/.},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\NGSIBB5F\Redmon und Farhadi - YOLOv3 An Incremental Improvement.pdf}
}

@inproceedings{redmonYouOnlyLook2016,
  title = {You {{Only Look Once}}: {{Unified}}, {{Real-Time Object Detection}}},
  shorttitle = {You {{Only Look Once}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  date = {2016-06},
  pages = {779--788},
  publisher = {IEEE},
  location = {Las Vegas, NV, USA},
  doi = {10.1109/CVPR.2016.91},
  url = {http://ieeexplore.ieee.org/document/7780460/},
  urldate = {2024-03-04},
  abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.},
  eventtitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4673-8851-1},
  langid = {english},
  keywords = {Methods},
  file = {C:\Users\noiri\Zotero\storage\53C78TH7\Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf}
}

@article{riveraUnmannedGroundVehicle2019,
  title = {Unmanned {{Ground Vehicle Modelling}} in {{Gazebo}}/{{ROS-Based Environments}}},
  author = {Rivera, Zandra B. and De Simone, Marco C. and Guida, Domenico},
  date = {2019-06},
  journaltitle = {Machines},
  volume = {7},
  number = {2},
  pages = {42},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2075-1702},
  doi = {10.3390/machines7020042},
  url = {https://www.mdpi.com/2075-1702/7/2/42},
  urldate = {2024-12-09},
  abstract = {The fusion of different technologies is the base of the fourth industrial revolution. Companies are encouraged to integrate new tools in their production processes in order to improve working conditions and increase productivity and production quality. The integration between information, communication technologies and industrial automation can create highly flexible production models for products and services that can be customized through real-time interactions between consumer, production and machinery throughout the production process. The future of production, therefore, depends on increasingly intelligent machinery through the use of digital systems. The key elements for future integrated devices are intelligent systems and machines, based on human–machine interaction and information sharing. To do so, the implementation of shared languages that allow different systems to dialogue in a simple way is necessary. In this perspective, the use of advanced prototyping tools like Open-Source programming systems, the development of more detailed multibody models through the use of CAD software and the use of self-learning techniques will allow for developing a new class of machines capable of revolutionizing our companies. The purpose of this paper is to present a waypoint navigation activity of a custom Wheeled Mobile Robot (WMR) in an available simulated 3D indoor environment by using the Gazebo simulator. Gazebo was developed in 2002 at the University of Southern California. The idea was to create a high-fidelity simulator that gave the possibility to simulate robots in outdoor environments under various conditions. In particular, we wanted to test the high-performance physics Open Dynamics Engine (ODE) and the sensors feature present in Gazebo for prototype development activities. This choice was made for the possibility of emulating not only the system under analysis, but also the world in which the robot will operate. Furthermore, the integration tools available with Solidworks and Matlab-Simulink, well known commercial platforms of modelling and robotics control respectively, are also explored.},
  issue = {2},
  langid = {english},
  keywords = {gazebo,Matlab,multibody dynamics,robotics,wheeled mobile robot},
  file = {C:\Users\noiri\Zotero\storage\JK4BAJF6\Rivera et al. - 2019 - Unmanned Ground Vehicle Modelling in GazeboROS-Based Environments.pdf}
}

@online{roboticsunveiledROS2Part122024,
  title = {{{ROS2 Part}} 12 - {{ROS2 Digital Twin}}},
  author = {RoboticsUnveiled},
  date = {2024-05-21T04:35:21+02:00},
  url = {https://www.roboticsunveiled.com/ros2-ros2-digital-twin/},
  urldate = {2024-08-15},
  abstract = {In this post we present an overview on the concept of ROS2 Digital Twins.},
  langid = {american},
  organization = {ROS2 Part 12 – ROS2 Digital Twin},
  file = {C:\Users\noiri\Zotero\storage\X6QWJYAU\ros2-ros2-digital-twin.html}
}

@online{ROS2Foxglove,
  title = {{{ROS}} 2 | {{Foxglove Docs}}},
  url = {https://docs.foxglove.dev/docs/connecting-to-data/frameworks/ros2},
  urldate = {2025-03-31},
  abstract = {Load local and remote MCAP files containing ROS 2 data, or connect directly to a live ROS 2 stack.},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\CPKY7CXE\ros2.html}
}

@online{RunningROS2,
  title = {Running {{ROS}} 2 on {{Multiple Machines}} | {{Husarion}}},
  url = {https://husarion.com/tutorials/ros2-tutorials/6-robot-network/},
  urldate = {2025-03-03},
  abstract = {Learn to configure ROS for efficient information exchange among multiple robots on both local networks and the Internet. Gain the power to command all your robots from a single location with ease.},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\A3CRZMU9\6-robot-network.html}
}

@online{schwabFourthIndustrialRevolution2016,
  title = {The {{Fourth Industrial Revolution}}: What It Means and How to Respond},
  shorttitle = {The {{Fourth Industrial Revolution}}},
  author = {Schwab, Klaus},
  date = {2016-01-14},
  url = {https://www.weforum.org/stories/2016/01/the-fourth-industrial-revolution-what-it-means-and-how-to-respond/},
  urldate = {2025-03-17},
  abstract = {The Fourth Industrial Revolution: what it means and how to respond, by Klaus Schwab},
  langid = {english},
  organization = {World Economic Forum},
  file = {C:\Users\noiri\Zotero\storage\GBITYJMH\the-fourth-industrial-revolution-what-it-means-and-how-to-respond.html}
}

@online{SettingNodeExporter,
  title = {Setting {{Up Node Exporter}} - {{Techdox Docs}}},
  url = {https://docs.techdox.nz/node-exporter/},
  urldate = {2025-03-27},
  abstract = {The Node Exporter is a project that is maintained through the Prometheus project.},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\744L5Q2C\node-exporter.html}
}

@online{SettingOdometryNav2,
  title = {Setting {{Up Odometry}} — {{Nav2}} 1.0.0 Documentation},
  url = {https://docs.nav2.org/setup_guides/odom/setup_odom.html},
  urldate = {2024-12-06},
  file = {C:\Users\noiri\Zotero\storage\YC4X894P\setup_odom.html}
}

@article{songMechanicalEfficiencyKinematics1988,
  title = {The Mechanical Efficiency and Kinematics of Pantograph-Type Manipulators},
  author = {Song, Shin-Min and Lee, Jong-Kil},
  date = {1988-03-01},
  journaltitle = {KSME Journal},
  shortjournal = {KSME Journal},
  volume = {2},
  number = {1},
  pages = {69--78},
  issn = {1738-494X},
  doi = {10.1007/BF02944079},
  url = {https://doi.org/10.1007/BF02944079},
  urldate = {2025-03-03},
  abstract = {Pantograph mechanism has been well known for its motion feature of decoupled kinematics. Planar pantograph mechanism has been extensively used in machinery since the seventeenth century. Recently, three dimensional pantographs have been used in walking machine leg and manipulator designs. This is because, the pantograph mechanism possesses the following advantages decoupled kinematics, higher energy efficiency, good rigidity, less link inertia and compact drive systems. In this paper, the mechanical efficiency of the kinematics of pantograph type manipulators are studied. The mechanical efficiency of pantograph mechanisms and conventional open-chain and closed-chain type manipulators are studied and evaluated using the concept of modified geometric work. The kinematics of six-d.o.f., pantograph type manipulators are studied and special mechanisms which simplify the kinematics are introduced. The computational complexity of both Cartesian and cylindrical type pantograph manipulators are evaluated and compared with a PUMA type manipulator.},
  langid = {english},
  keywords = {Inverse Position Analysis,Mechanical Efficiency,Pantograph Mechanism},
  file = {C:\Users\noiri\Zotero\storage\43L7GNV4\Song und Lee - 1988 - The mechanical efficiency and kinematics of pantograph-type manipulators.pdf}
}

@article{staczekDigitalTwinApproach2021,
  title = {A {{Digital Twin Approach}} for the {{Improvement}} of an {{Autonomous Mobile Robots}} ({{AMR}}’s) {{Operating Environment}}—{{A Case Study}}},
  author = {Stączek, Paweł and Pizoń, Jakub and Danilczuk, Wojciech and Gola, Arkadiusz},
  date = {2021-11-25},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {21},
  number = {23},
  pages = {7830},
  issn = {1424-8220},
  doi = {10.3390/s21237830},
  url = {https://www.mdpi.com/1424-8220/21/23/7830},
  urldate = {2024-11-16},
  abstract = {The contemporary market creates a demand for continuous improvement of production, service, and management processes. Increasingly advanced IT technologies help designers to meet this demand, as they allow them to abandon classic design and design-testing methods in favor of techniques that do not require the use of real-life systems and thus significantly reduce the costs and time of implementing new solutions. This is particularly important when re-engineering production and logistics processes in existing production companies, where physical testing is often infeasible as it would require suspension of production for the testing period. In this article, we showed how the Digital Twin technology can be used to test the operating environment of an autonomous mobile robot (AMR). In particular, the concept of the Digital Twin was used to assess the correctness of the design assumptions adopted for the early phase of the implementation of an AMR vehicle in a company’s production hall. This was done by testing and improving the case of a selected intralogistics task in a potentially “problematic” part of the shop floor with narrow communication routes. Three test scenarios were analyzed. The results confirmed that the use of digital twins could accelerate the implementation of automated intralogistics systems and reduce its costs.},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\44QC3UP2\Stączek et al. - 2021 - A Digital Twin Approach for the Improvement of an Autonomous Mobile Robots (AMR’s) Operating Environ.pdf}
}

@online{SwarmMode0800,
  title = {Swarm Mode},
  year = {07:31:40 -0800 -0800},
  url = {https://docs.docker.com/engine/swarm/},
  urldate = {2025-03-23},
  abstract = {Docker Engine Swarm mode overview},
  langid = {english},
  organization = {Docker Documentation}
}

@online{SwarmModeKey0200,
  title = {Swarm Mode Key Concepts},
  year = {15:26:47 +0200 +0200},
  url = {https://docs.docker.com/engine/swarm/key-concepts/},
  urldate = {2025-03-23},
  abstract = {Introducing key concepts for Docker Engine swarm mode},
  langid = {english},
  organization = {Docker Documentation},
  file = {C:\Users\noiri\Zotero\storage\TVKHQCXS\key-concepts.html}
}

@inproceedings{takayaSimulationEnvironmentMobile2016,
  title = {Simulation Environment for Mobile Robots Testing Using {{ROS}} and {{Gazebo}}},
  booktitle = {2016 20th {{International Conference}} on {{System Theory}}, {{Control}} and {{Computing}} ({{ICSTCC}})},
  author = {Takaya, Kenta and Asai, Toshinori and Kroumov, Valeri and Smarandache, Florentin},
  date = {2016-10},
  pages = {96--101},
  publisher = {IEEE},
  location = {Sinaia},
  doi = {10.1109/ICSTCC.2016.7790647},
  url = {https://ieeexplore.ieee.org/document/7790647/},
  urldate = {2024-11-16},
  eventtitle = {2016 20th {{International Conference}} on {{System Theory}}, {{Control}} and {{Computing}} ({{ICSTCC}})},
  isbn = {978-1-5090-2720-0}
}

@video{techdoxEffortlessServerMonitoring2023,
  entrysubtype = {video},
  title = {Effortless {{Server Monitoring}}: {{Install Grafana}}, {{Prometheus}} \& {{Node Exporter}} with {{Docker}}!},
  shorttitle = {Effortless {{Server Monitoring}}},
  editor = {{Techdox}},
  editortype = {director},
  date = {2023-12-30},
  url = {https://www.youtube.com/watch?v=yrscZ-kGc_Y},
  urldate = {2025-03-27}
}

@online{TraefikProxyDocumentation,
  title = {Traefik {{Proxy Documentation}} - {{Traefik}}},
  url = {https://doc.traefik.io/traefik/},
  urldate = {2025-04-05},
  file = {C:\Users\noiri\Zotero\storage\2WSW7ZEA\traefik.html}
}

@online{Triangulation_YDLIDAR|FocusLidarSensor,
  title = {Triangulation\_{{YDLIDAR}}|{{Focus}} on Lidar Sensor Solutions},
  url = {https://www.ydlidar.com/products/Triangulation.html},
  urldate = {2025-04-11},
  file = {C:\Users\noiri\Zotero\storage\2HVLAWQ7\Triangulation.html}
}

@online{UnmetDependenciesInstalling,
  title = {Unmet Dependencies Installing Ros-Jazzy-Desktop on {{Ubuntu}} 24.04 {{LTS}} · {{Issue}} \#1621 · Ros2/Ros2},
  url = {https://github.com/ros2/ros2/issues/1621},
  urldate = {2025-04-12},
  abstract = {Bug report Ubuntu 24.04.1 LTS, kernel 6.9.1 Steps to reproduce issue Follow steps from https://docs.ros.org/en/jazzy/Installation/Ubuntu-Install-Debs.html Expected behavior Install OK Actual behavi...},
  langid = {english},
  organization = {GitHub},
  file = {C:\Users\noiri\Zotero\storage\2GYQWVN8\1621.html}
}

@online{UpdatedGuideDocker2023,
  title = {An {{Updated Guide}} to {{Docker}} and {{ROS}} 2 – {{Robotic Sea Bass}}},
  date = {2023-07-09},
  url = {https://roboticseabass.com/2023/07/09/updated-guide-docker-and-ros2/},
  urldate = {2025-03-05},
  langid = {american},
  file = {C:\Users\noiri\Zotero\storage\ZCD2NB4C\updated-guide-docker-and-ros2.html}
}

@software{UrdfXMLROS,
  title = {Urdf/{{XML}} - {{ROS Wiki}}},
  url = {https://wiki.ros.org/urdf/XML},
  urldate = {2024-11-19},
  file = {C:\Users\noiri\Zotero\storage\TWLJPF5H\XML.html}
}

@online{UseROS2,
  title = {Use {{ROS}} 2 to Interact with {{Gazebo}} — {{Gazebo}} Ionic Documentation},
  url = {https://gazebosim.org/docs/latest/ros2_integration/},
  urldate = {2024-12-05}
}

@online{voasDraftConsiderationsDigital2021,
  title = {({{Draft}}) {{Considerations}} for {{Digital Twins Standards}}},
  author = {Voas, Jeff},
  date = {2021-04-16},
  doi = {10.6028/NIST.IR.8356-draft},
  url = {https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8356-draft.pdf},
  urldate = {2024-11-16},
  pubstate = {prepublished},
  file = {C:\Users\noiri\Zotero\storage\NJE52RHU\Voas - 2021 - (Draft) Considerations for Digital Twins Standards.pdf}
}

@misc{wahdeINTRODUCTIONAUTONOMOUSROBOTS2016,
  title = {{{INTRODUCTION TO AUTONOMOUS ROBOTS}}},
  author = {Wahde, Mattias},
  date = {2016},
  langid = {english},
  file = {C:\Users\noiri\Zotero\storage\Q5J7WWVZ\Wahde - INTRODUCTION TO AUTONOMOUS ROBOTS.pdf}
}

@online{WebhooksDocumentationGitHub,
  title = {Webhooks Documentation - {{GitHub Enterprise Server}} 3.14 {{Docs}}},
  url = {https://docs-internal.github.com/en/enterprise-server@3.14/webhooks},
  urldate = {2025-03-28},
  abstract = {Webhooks can let your integrations take an action in response to events that occur on GitHub.},
  langid = {english},
  organization = {GitHub Docs},
  file = {C:\Users\noiri\Zotero\storage\KYIHA8QN\webhooks.html}
}

@online{WelcomeOxfordNanopore,
  title = {Welcome to {{Oxford Nanopore Technologies}}},
  url = {https://nanoporetech.com/},
  urldate = {2025-03-10},
  abstract = {Discover a new generation of molecular sensing technology which offers short to ultra-long native DNA and RNA reads.},
  langid = {british},
  organization = {Oxford Nanopore Technologies},
  file = {C:\Users\noiri\Zotero\storage\RN5G3G9H\nanoporetech.com.html}
}

@online{WhatCloudComputing2023,
  title = {What {{Is Cloud Computing}}? | {{IBM}}},
  shorttitle = {What {{Is Cloud Computing}}?},
  date = {2023-04-25T00:00:00.000},
  url = {https://www.ibm.com/topics/cloud-computing},
  urldate = {2024-08-16},
  abstract = {Cloud computing enables customers to use infrastructure and applications by way of the internet, without installing and maintaining them on premises.},
  langid = {american}
}

@online{WhatContainer0100,
  title = {What Is a Container?},
  year = {11:25:13 +0100 +0100},
  url = {https://docs.docker.com/get-started/docker-concepts/the-basics/what-is-a-container/},
  urldate = {2025-03-25},
  abstract = {What is a container? This concept page will teach you about containers and provide a quick hands-on where you will run your first container.},
  langid = {english},
  organization = {Docker Documentation},
  file = {C:\Users\noiri\Zotero\storage\M3KUIACG\what-is-a-container.html}
}

@online{WhatEdgeComputing,
  title = {What {{Is Edge Computing}}? {{Everything You Need}} to {{Know}}},
  shorttitle = {What {{Is Edge Computing}}?},
  url = {https://www.techtarget.com/searchdatacenter/definition/edge-computing},
  urldate = {2024-08-16},
  abstract = {Learn about edge computing, how it works and the importance of its role in the growth of 5G. Discover why edge computing matters, including benefits and use cases.},
  langid = {english},
  organization = {Data Center},
  file = {C:\Users\noiri\Zotero\storage\HV28A3NB\edge-computing.html}
}

@online{WhyUseCompose0100,
  title = {Why Use {{Compose}}?},
  year = {16:22:09 +0100 +0100},
  url = {https://docs.docker.com/compose/intro/features-uses/},
  urldate = {2025-03-23},
  abstract = {Key benefits and use cases of Docker Compose},
  langid = {english},
  organization = {Docker Documentation},
  file = {C:\Users\noiri\Zotero\storage\RU76BGK6\features-uses.html}
}

@software{YDLIDARYdlidar_ros2_driver2025,
  title = {{{YDLIDAR}}/Ydlidar\_ros2\_driver},
  date = {2025-04-09T00:45:36Z},
  origdate = {2020-06-17T07:19:26Z},
  url = {https://github.com/YDLIDAR/ydlidar_ros2_driver},
  urldate = {2025-04-11},
  abstract = {ydlidar driver package under ros2},
  organization = {Shenzhen Yuedeng Technology Co.,Ltd.}
}

@software{YDLIDARYdlidar_ros2_driver2025a,
  title = {{{YDLIDAR}}/Ydlidar\_ros2\_driver},
  date = {2025-04-09T00:45:36Z},
  origdate = {2020-06-17T07:19:26Z},
  url = {https://github.com/YDLIDAR/ydlidar_ros2_driver},
  urldate = {2025-04-15},
  abstract = {ydlidar driver package under ros2},
  organization = {Shenzhen Yuedeng Technology Co.,Ltd.}
}
